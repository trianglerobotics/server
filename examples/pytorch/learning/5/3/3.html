<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>API Documentation</title>
    <link rel="stylesheet" href="http://121.184.63.113:4000/css/basic.css">
    <link rel="stylesheet" href="http://121.184.63.113:4000/css/default.min.css">
    <script src="http://121.184.63.113:4000/js/highlight.js"></script>
    <style>
      .container {
        font-family: 'MyFont', Arial, sans-serif;
      }
      .code {
        font-family: 'MyFont', Arial, sans-serif;
      }
      .language-python {
        font-family: 'MyFont', Arial, sans-serif;
      }
    </style>
    <script>
      window.MathJax = {
        loader: { load: ['[tex]/ams'] },
        tex: {
          packages: ['base', 'ams'],
          inlineMath: [['\\(', '\\)'], ['$', '$']],
        },
        chtml: {
          fontURL: 'http://121.184.63.113:4000/fonts/woff-v2' // CDN 경로 명시
        }
      };
    </script>
    <script type="text/javascript" id="MathJax-script" async
    src="http://121.184.63.113:4000/js/tex-chtml.js">
    </script>
    <script>hljs.initHighlightingOnLoad();</script>
  </head>
  <body class="api-docs">

    

     <!-- explain-1 -->
    <div class="container">
      <h1>파이토치 기초</h1>
      <hr>
      <h2 style="margin-bottom: 3px;">파이토치 기반 선형 회기 구현(클래스)</h2>
      <h3>선형 회기 구현 -1 : 목표 설정</h3>
      <p>자동차가 1초동안 2M, 2초동한 4M, 3초동안 6M를 이동했다는 데이터가 있다고 가정합니다. 이를 가장 잘 나타내는 함수를 구하고자 합니다</p>
    </div>
    <div class="container">
      <h3>선형 회기 구현 -2 : 라이브러리 가져오기</h3>
    </div>

    <div class="code">
      <h3>A 실행하여 파이토치를 가져오세요</h3>
      <div class="code_div">
        <pre>
          <code class="language-python">
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim</code>
        </pre>
      </div>
      <br></br>
    </div>

    <div class="container">
      <h3>선형 회기 구현 -3 : 훈련 데이터셋의 구성</h3>
    </div>

    <div class="code">
      <h3>B 실행하여 데이터를 생성하세요</h3>
      <div class="code_div">
        <pre>
          <code class="language-python">
# 훈련 데이터셋
x_train = torch.FloatTensor([[1], [2], [3]])
y_train = torch.FloatTensor([[2], [4], [6]])</code>
        </pre>
      </div>
      <br></br>
    </div>

    <div class="container">
      <h3>선형 회기 구현 -4 : 함수 가설 설정</h3>
      <p style="overflow-x: auto;">
        torch.nn.Linear 인자로 1, 1을 사용합니다. 하나의 입력 
        에 대해서 하나의 출력 을 가지므로, 입력 차원과 출력 차원 모두 1을 인수로 사용합니다</p>
    </div>

    <div class="code">
      <h3>C 실행하여 함수를 생성합니다</h3>
      <div class="code_div">
        <pre>
          <code class="language-python">
model = nn.Linear(1,1)</code>
        </pre>
      </div>
      <br></br>
    </div>

    <div class="container">
      <h3>선형 회기 구현 -5 : 비용 함수 설정</h3>
      <p>선형 회기의 비용 함수는 평균 제곱 오차(Mean Squared Error, MSE)로 정의됩니다</p>
      <div style="font-size: large;">
        \[
        cost(W, b) = \frac{1}{n} \sum_{i=1}^{n} (H(x^{(i)}) - y^{(i)})^2
        \]
      </div>
    </div>

    <div class="code">
      <h3>D 손실함수를 생성합니다</h3>
      <div class="code_div">
        <pre>
          <code class="language-python">
cost = F.mse_loss(prediction, y_train)
print(cost)</code>
        </pre>
      </div>
      <br></br>
    </div>

    <div class="container">
      <h3>선형 회기 구현 -7 : 경사하강법 구현하기</h3>
      <p>PyTorch의 torch.optim.SGD는 Stochastic Gradient Descent(확률적 경사 하강법) 최적화 알고리즘을 구현한 클래스입니다. 딥러닝 모델의 학습 중 손실(loss)을 최소화하기 위해 가중치를 업데이트하는 데 사용됩니다.</p>
    </div>

    <div class="code">
      <h3>E 경사하강법을 구현합니다</h3>
      <div class="code_div">
        <pre>
          <code class="language-python">
# optimizer 설정. 경사 하강법 SGD를 사용하고 learning rate를 의미하는 lr은 0.01
optimizer = torch.optim.SGD(model.parameters(), lr=0.01) 
# 경사 하강법 수행
prediction = model(x_train)
# cost 계산
cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수
# cost로 H(x) 개선하는 부분
# gradient를 0으로 초기화
optimizer.zero_grad()
# 비용 함수를 미분하여 gradient 계산
cost.backward() # backward 연산
# W와 b를 업데이트
optimizer.step()</code>
        </pre>
      </div>
      <br></br>
    </div>

    <div class="container">
      <h3>선형 회기 구현 -8 : 전체 코드</h3>
    </div>

    <div class="code">
      <h3>F 실행하여 전체 코드를 확인하세요</h3>
      <div class="code_div">
        <pre>
          <code class="language-python">
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F

# 초기화
w = torch.zeros(1, requires_grad=True)  # 가중치 w
b = torch.zeros(1, requires_grad=True)  # 편향 b

# 훈련 데이터셋
x_train = torch.FloatTensor([[1], [2], [3]])
y_train = torch.FloatTensor([[2], [4], [6]])

model = nn.Linear(1,1)

# optimizer 설정. 경사 하강법 SGD를 사용하고 learning rate를 의미하는 lr은 0.01
optimizer = torch.optim.SGD(model.parameters(), lr=0.01) 

nb_epochs = 2000
for epoch in range(nb_epochs+1):

    # H(x) 계산
    prediction = model(x_train)

    # cost 계산
    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수

    # cost로 H(x) 개선하는 부분
    # gradient를 0으로 초기화
    optimizer.zero_grad()
    # 비용 함수를 미분하여 gradient 계산
    cost.backward() # backward 연산
    # W와 b를 업데이트
    optimizer.step()

    if epoch % 100 == 0:
    # 100번마다 로그 출력
      print('Epoch {:4d}/{} Cost: {:.6f}'.format(
          epoch, nb_epochs, cost.item()))</code>
        </pre>
      </div>
      <br></br>
    </div>


    <div class="container">
      <p>© JAJUCHA, www.jajucha.com</p>
    </div>


    
  </body>
</html>
