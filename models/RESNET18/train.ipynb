{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output  # 실시간 그래프 갱신\n",
    "import os\n",
    "\n",
    "# 디바이스 설정 (GPU 사용 가능 여부 확인)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Path to the folder you want to delete\n",
    "folder_path = \"checkpoints/train/weights\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    # 폴더 내의 모든 파일과 하위 폴더를 삭제\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            # 파일이나 심볼릭 링크인 경우 삭제\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "                print(f\"파일 '{file_path}'이 삭제되었습니다.\")\n",
    "            # 디렉토리인 경우 삭제\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "                print(f\"폴더 '{file_path}'이 삭제되었습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"'{file_path}'를 삭제하는 중 에러가 발생했습니다: {e}\")\n",
    "else:\n",
    "    print(f\"폴더 '{folder_path}'가 존재하지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "EPOCH = 20        # 총 학습 에포크 수\n",
    "pre_epoch = 0      # 시작 에포크 (재학습 시 사용)\n",
    "BATCH_SIZE = 16    # 배치 크기\n",
    "LR = 0.01          # 학습률\n",
    "TRAIN_DATA_PERCENT = 0.8  # 훈련 데이터 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "        self.data = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        data = []\n",
    "        for cls in self.classes:\n",
    "            class_path = os.path.join(self.root_dir, cls)\n",
    "            for img_name in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                label = self.class_to_idx[cls]\n",
    "                data.append((img_path, label))\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# 데이터 전처리 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 전체 데이터셋 로드\n",
    "dataset = CustomDataset(root_dir=\"data\", transform=transform)\n",
    "\n",
    "# 훈련과 테스트 비율 설정 (80% 훈련, 20% 테스트)\n",
    "train_size = int(TRAIN_DATA_PERCENT * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# 랜덤하게 나누기\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# 데이터 로더 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"훈련 데이터 수: {len(train_dataset)}, 테스트 데이터 수: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 수 확인\n",
    "classes = dataset.classes  # 원본 데이터셋에서 클래스 정보 추출\n",
    "NUM_CLASSES = len(classes)\n",
    "\n",
    "# ResNet-18 모델 불러오기 및 수정\n",
    "net = models.resnet18()  # 사전 학습된 가중치를 사용하지 않음\n",
    "num_ftrs = net.fc.in_features\n",
    "net.fc = nn.Linear(num_ftrs, NUM_CLASSES)  # 출력 차원을 클래스 수로 변경\n",
    "net = net.to(device)  # 모델을 디바이스로 이동"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 및 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 루프 시작\n",
    "# 훈련 및 테스트 결과를 기록할 리스트\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# 훈련 루프 시작\n",
    "for epoch in range(EPOCH):\n",
    "    print(f'\\n에폭: {epoch + 1}')\n",
    "    net.train()\n",
    "    sum_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # 데이터 준비\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward 및 Backward 연산\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 손실 및 정확도 계산\n",
    "        sum_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.data).sum().item()\n",
    "\n",
    "    # 에폭당 훈련 손실 및 정확도 기록\n",
    "    train_losses.append(sum_loss / len(train_loader))\n",
    "    train_accuracies.append(100. * correct / total)\n",
    "\n",
    "    # 모델 저장\n",
    "    model_scripted = torch.jit.script(net)\n",
    "    model_scripted.save(os.path.join('checkpoints/train/weights', f'resnet_epoch_{epoch + 1}.pt'))\n",
    "\n",
    "    # 테스트 데이터로 정확도 측정\n",
    "    print('테스트 진행 중...')\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels.data).sum().item()\n",
    "\n",
    "    test_accuracy = 100. * correct / total\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # 그래프 실시간 출력\n",
    "    clear_output(wait=True)  # 이전 출력 지우기\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # 훈련 손실 그래프\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, epoch + 2), train_losses, marker='o', label='Train Loss')\n",
    "    plt.title('Train Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # 훈련 및 테스트 정확도 그래프\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epoch + 2), train_accuracies, marker='o', label='Train Accuracy')\n",
    "    plt.plot(range(1, epoch + 2), test_accuracies, marker='o', label='Test Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 현재 정확도 출력\n",
    "    print(f'[에폭 {epoch + 1}] 훈련 손실: {train_losses[-1]:.3f} | '\n",
    "          f'훈련 정확도: {train_accuracies[-1]:.3f}% | '\n",
    "          f'테스트 정확도: {test_accuracies[-1]:.3f}%')\n",
    "\n",
    "print(f'훈련이 완료되었습니다. 총 에포크 수는 {EPOCH}입니다.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
