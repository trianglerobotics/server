{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CELL-1 코드리뷰 \n",
    "\n",
    "- <strong>NUM_CLASSES = </strong> -> 설정했던 클래스의 갯수를 입력합니다\n",
    "- 모델에 첫번째 input layer를 생성할때 필요합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES =  ###클래스 갯수를 입력하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CELL-2 코드리뷰 \n",
    "\n",
    "- <strong>EPOCH = 150</strong> -> 전체 훈련 데이터를 150번 반복합니다\n",
    "- <strong>pre_epoch = 0</strong> -> 처음부터 시작합니다\n",
    "- <strong>BATCH_SIZE = 16</strong> -> 16개의 샘플이 동시에 모델에 입력되고, 이 데이터를 기반으로 모델의 가중치가 업데이트됩니다\n",
    "- <strong>LR = 0.01</strong> -> 모델이 각 배치마다 가중치를 업데이트할 때 0.01만큼 조정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "EPOCH = 150\n",
    "pre_epoch = 0\n",
    "BATCH_SIZE = 16\n",
    "LR = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "print(os.getcwd())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "        self.data = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        data = []\n",
    "        for cls in self.classes:\n",
    "            class_path = os.path.join(self.root_dir, cls)\n",
    "            for img_name in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                data.append((img_path, self.class_to_idx[cls]))\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Import the ResNet-18 model\n",
    "resnet18 = models.resnet18(pretrained=False)  # Set pretrained=True to load weights pre-trained on ImageNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset and preprocessing\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Change input size\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Change input size\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Set the directory\n",
    "current_directory = os.getcwd()\n",
    "file_path_train = \"data\"\n",
    "file_path_test = \"data\"\n",
    "\n",
    "custom_dataset_train = CustomDataset(root_dir=file_path_train, transform=transform_train)\n",
    "custom_dataset_test = CustomDataset(root_dir=file_path_test, transform=transform_test)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(custom_dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(custom_dataset_test, batch_size=8, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ResNet18\n",
    "net = models.resnet18(pretrained=False)  # Import ResNet18 from torchvision.models\n",
    "num_ftrs = net.fc.in_features\n",
    "net.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function & optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(pre_epoch, EPOCH):\n",
    "    print('\\nEpoch: %d' % (epoch + 1))\n",
    "    net.train()\n",
    "    sum_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Prepare dataset\n",
    "        length = len(trainloader)\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward & backward\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print accuracy & loss in each batch\n",
    "        sum_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.data).cpu().sum()\n",
    "        print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% '\n",
    "              % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
    "    \n",
    "\n",
    "    model_scripted = torch.jit.script(net)\n",
    "    model_scripted.save(os.path.join('checkpoints', f'resnet_epoch_{epoch + 1}.pt'))\n",
    "    \n",
    "    \n",
    "    # Get accuracy with the test dataset in each epoch\n",
    "    print('Waiting Test...')\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in testloader:\n",
    "            net.eval()\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "        print('Test\\'s accuracy is: %.3f%%' % (100. * correct / total))\n",
    "print('Training has finished, total epoch is %d' % EPOCH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
