{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image as Img\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, Image\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module): #Resnet18 model\n",
    "    def __init__(self, ResidualBlock, num_classes=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),  # Change kernel_size, stride, and padding\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # Add MaxPool2d\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64, 2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)        \n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)        \n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 7)  # Change average pooling to have a kernel_size of 7 to match input size\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out = out + self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    return ResNet(ResidualBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@8.992] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video2): can't open camera by index\n",
      "[ERROR:0@9.509] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245fd96a25b840edb5728edaa042ba43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not open webcam.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load the model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = ResNet18().to(device)\n",
    "    checkpoint = torch.load('/home/tr/server/datasets/test/train/checkpoints/resnet_model_epoch_8.pth', map_location=device)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    net.eval()\n",
    "    \n",
    "    # Define the transform to match model's input size\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Open a connection to the webcam (default is device 0)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    image_widget = widgets.Image()\n",
    "    display(image_widget)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "    try:\n",
    "        # Continuously capture frames from the webcam\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Error: Could not read frame.\")\n",
    "                break\n",
    "\n",
    "            # Convert frame to PIL image\n",
    "            image = Img.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            # Apply the transform\n",
    "            image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "            # Perform inference\n",
    "            with torch.no_grad():\n",
    "                outputs = net(image)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                prediction = predicted.item()\n",
    "\n",
    "            # Display the prediction on the frame\n",
    "            label = f\"Predicted Class: {prediction}\"\n",
    "            cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            ret, jpeg = cv2.imencode('.jpg', frame)\n",
    "            if not ret:\n",
    "                break\n",
    "            image_widget.value = jpeg.tobytes()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        cap.release()\n",
    "        print(\"Video stream stopped.\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
